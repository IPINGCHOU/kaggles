{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2466f483-01bb-482f-bf6a-58144b1c76e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the path to the large CSV file\n",
    "input_file_path = '/Workspace/Repos/aeo-chiyou-ip@aeondic.onmicrosoft.com/kaggles/March_Machine_Learning_Mania_2025/submission.csv'\n",
    "\n",
    "# Define the output directory for the chunks\n",
    "output_dir = './outputs'\n",
    "\n",
    "# Define the maximum size for each chunk (in bytes)\n",
    "max_chunk_size = 10485760  # 10 MB\n",
    "\n",
    "# Read the CSV file in chunks\n",
    "chunk_size = 100000  # Number of rows per chunk (adjust as needed)\n",
    "chunks = pd.read_csv(input_file_path, chunksize=chunk_size)\n",
    "\n",
    "print(f'Original file rows: {len(pd.read_csv(input_file_path))}')\n",
    "\n",
    "# Initialize variables\n",
    "chunk_index = 0\n",
    "current_chunk_size = 0\n",
    "current_chunk = pd.DataFrame()\n",
    "\n",
    "# Process each chunk\n",
    "for ci, chunk in enumerate(chunks):\n",
    "    chunk_size_bytes = chunk.memory_usage(deep=True).sum()\n",
    "    \n",
    "    if current_chunk_size + chunk_size_bytes > max_chunk_size:\n",
    "        # Save the current chunk to a CSV file without header\n",
    "        output_file_path = os.path.join(output_dir, f'chunk_{chunk_index}.csv')\n",
    "        current_chunk.to_csv(output_file_path, index=False, header=False)\n",
    "        \n",
    "        # Reset variables for the next chunk\n",
    "        chunk_index += 1\n",
    "        current_chunk_size = 0\n",
    "        current_chunk = pd.DataFrame()\n",
    "    \n",
    "    # Append the current chunk to the current_chunk DataFrame\n",
    "    current_chunk = pd.concat([current_chunk, chunk])\n",
    "    current_chunk_size += chunk_size_bytes\n",
    "\n",
    "    print(f'-Chunk: {chunk_index} len: {len(current_chunk)}')\n",
    "\n",
    "# Save the last chunk if it exists\n",
    "if not current_chunk.empty:\n",
    "    output_file_path = os.path.join(output_dir, f'chunk_{chunk_index}.csv')\n",
    "    current_chunk.to_csv(output_file_path, index=False, header=False)\n",
    "\n",
    "    print(f'Chunk: {chunk_index} len: {len(current_chunk)}')\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Define the source file path\n",
    "source_file_path = '/Workspace/Repos/aeo-chiyou-ip@aeondic.onmicrosoft.com/kaggles/March_Machine_Learning_Mania_2025/chunks_join.bat'\n",
    "# Define the destination file path\n",
    "destination_file_path = os.path.join(output_dir, 'chunks_join.bat')\n",
    "# Copy the file to the output directory\n",
    "shutil.copy(source_file_path, destination_file_path)\n",
    "print('Join bat cped')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "chunk_postprocess",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
