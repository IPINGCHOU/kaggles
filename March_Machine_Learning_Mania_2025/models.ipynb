{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ed97d3a-26e6-4a93-bdc7-4856ca55be5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "157f13ef-9938-4968-8e53-d74b33446b73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Essential Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e7cf51a-83f3-4153-a179-a7fc53b0924d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20edd4cd-80b2-4375-9158-07b6f68e7a62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "data_route = '/Workspace/Repos/aeo-chiyou-ip@aeondic.onmicrosoft.com/kaggles/March_Machine_Learning_Mania_2025/data'\n",
    "m_dfs, f_dfs = {}, {}\n",
    "m_dfs['season'] = pd.read_csv(os.path.join(data_route, 'MRegularSeasonDetailedResults.csv'))\n",
    "m_dfs['tournament'] = pd.read_csv(os.path.join(data_route, 'MNCAATourneyDetailedResults.csv'))\n",
    "m_dfs['seed'] = pd.read_csv(os.path.join(data_route, 'MNCAATourneySeeds.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dac5513b-6a38-4188-8acc-0a9be8f3413d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65f77594-0658-4499-9d51-19bcd320c0eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73e76be3-ab88-406b-aea2-babb42d06c78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_season = m_dfs['season'].copy()\n",
    "df_submission = pd.read_csv(os.path.join(data_route, \"SampleSubmissionStage1.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5089e59d-e9ef-4e17-82ac-9a6f4dd4a8c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Compute average team statistics from regular season games\n",
    "stat_cols = [\"WScore\", \"LScore\", \"WFGM\", \"WFGA\", \"WFGM3\", \"WFGA3\", \"WFTM\", \"WFTA\", \"WAst\", \"WTO\", \"WOR\", \"WDR\"]\n",
    "team_stats = df_season.groupby(\"WTeamID\").agg({col: \"mean\" for col in stat_cols}).reset_index()\n",
    "team_stats.rename(columns={\"WTeamID\": \"TeamID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2f73fdb-6280-4fbb-ba4e-f01c611c7ca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Create the training dataset from historical games\n",
    "df_train = df_season.copy()\n",
    "# Define Team1 as the team with the lower ID and Team2 as the one with the higher ID.\n",
    "df_train[\"Team1\"] = df_train[[\"WTeamID\", \"LTeamID\"]].min(axis=1)\n",
    "df_train[\"Team2\"] = df_train[[\"WTeamID\", \"LTeamID\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9d80232-ba43-4d53-abc0-b4d6bbecca57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e913f68-f3b9-435d-b33c-11f285bdbf63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Label = 1 if Team1 won (i.e., if WTeamID == Team1), else 0.\n",
    "df_train[\"Label\"] = (df_train[\"WTeamID\"] == df_train[\"Team1\"]).astype(int)\n",
    "# Drop original game statistics to avoid conflicts.\n",
    "df_train = df_train.drop(columns=stat_cols, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4747e5b-cbff-4954-9bc6-f01636c429c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Merge average statistics for Team1\n",
    "df_train = df_train.merge(team_stats, left_on=\"Team1\", right_on=\"TeamID\", how=\"left\")\n",
    "rename_dict_T1 = {col: col + \"_T1\" for col in stat_cols}\n",
    "df_train.rename(columns=rename_dict_T1, inplace=True)\n",
    "df_train.drop(\"TeamID\", axis=1, inplace=True)\n",
    "# Merge average statistics for Team2\n",
    "df_train = df_train.merge(team_stats, left_on=\"Team2\", right_on=\"TeamID\", how=\"left\", suffixes=(\"\", \"_T2\"))\n",
    "rename_dict_T2 = {col: col + \"_T2\" for col in stat_cols}\n",
    "df_train.rename(columns=rename_dict_T2, inplace=True)\n",
    "df_train.drop(\"TeamID\", axis=1, inplace=True)\n",
    "\n",
    "# Compute difference features for each game\n",
    "for col in stat_cols:\n",
    "    df_train[\"Diff_\" + col] = df_train[col + \"_T1\"] - df_train[col + \"_T2\"]\n",
    "\n",
    "feature_cols = [\"Diff_\" + col for col in stat_cols]\n",
    "X = df_train[feature_cols]\n",
    "y = df_train[\"Label\"]\n",
    "# Imputation (au cas o√π certaines valeurs manqueraient)\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18eb3565-33b1-480c-82be-a22e3bab45c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf9d3803-c3fa-4875-b503-8ab94dcbcb71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Create a stacking model using XGBoost, LightGBM and CatBoost as base learners and Logistic Regression as meta-model.\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "estimators = [\n",
    "    (\"xgb\", xgb_model),\n",
    "    (\"lgb\", lgb_model),\n",
    "]\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(max_iter=1000, random_state=42),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set using Brier score loss\n",
    "y_val_proba = stacking_model.predict_proba(X_val)[:, 1]\n",
    "brier = brier_score_loss(y_val, y_val_proba)\n",
    "print(\"Brier score loss on validation:\", brier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbdff5c0-ab38-4651-b08a-d6bb3cf836d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 5. Prepare predictions for the submission file\n",
    "# The submission file contains an \"ID\" column in the format \"2025_Team1_Team2\" (with Team1 < Team2)\n",
    "df_submission[[\"Season\", \"Team1\", \"Team2\"]] = df_submission[\"ID\"].str.split(\"_\", expand=True)\n",
    "df_submission[\"Team1\"] = df_submission[\"Team1\"].astype(int)\n",
    "df_submission[\"Team2\"] = df_submission[\"Team2\"].astype(int)\n",
    "\n",
    "# Merge average statistics for Team1 in the submission\n",
    "df_sub = df_submission.merge(team_stats, left_on=\"Team1\", right_on=\"TeamID\", how=\"left\")\n",
    "df_sub.rename(columns=rename_dict_T1, inplace=True)\n",
    "df_sub.drop(\"TeamID\", axis=1, inplace=True)\n",
    "\n",
    "# Merge average statistics for Team2 in the submission\n",
    "df_sub = df_sub.merge(team_stats, left_on=\"Team2\", right_on=\"TeamID\", how=\"left\", suffixes=(\"\", \"_T2\"))\n",
    "df_sub.rename(columns=rename_dict_T2, inplace=True)\n",
    "df_sub.drop(\"TeamID\", axis=1, inplace=True)\n",
    "\n",
    "# Compute difference features for submission\n",
    "for col in stat_cols:\n",
    "    df_sub[\"Diff_\" + col] = df_sub[col + \"_T1\"] - df_sub[col + \"_T2\"]\n",
    "\n",
    "X_sub = df_sub[feature_cols]\n",
    "X_sub = imputer.transform(X_sub)  # Apply the same imputation as on training data\n",
    "\n",
    "# Predict probabilities for each matchup using the stacking model\n",
    "submission_proba = stacking_model.predict_proba(X_sub)[:, 1]\n",
    "df_submission[\"Pred\"] = submission_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22b66334-f8f0-4ffb-9ea5-e7becda6f24a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c8aba55-7518-4b39-9f8e-dea7d059a088",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Feature importance from the LightGBM model (extracted from the stacking)\n",
    "# Ensure that the LightGBM model is among your stacking estimators\n",
    "lgb_model = stacking_model.named_estimators_[\"lgb\"]\n",
    "# Extract the feature importances\n",
    "lgb_importance = lgb_model.feature_importances_\n",
    "# Convert to a DataFrame for easier visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": feature_cols,\n",
    "    \"Importance\": lgb_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Importance\", y=\"Feature\", data=importance_df, palette=\"viridis\")\n",
    "plt.title(\"Feature Importance from LightGBM\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6e9db85-d849-438a-97a0-07f10a5dab7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d4e265c-eb80-4834-9cc3-d9077b15542c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_submission[[\"ID\", \"Pred\"]].to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "models",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
